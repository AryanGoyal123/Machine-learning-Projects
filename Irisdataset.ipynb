{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Irisdataset.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNxrfILeAzNX7ANA0l5LKuE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AryanGoyal123/Machine-learning-Projects/blob/main/Irisdataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h8YNHEIJuLba"
      },
      "outputs": [],
      "source": [
        "# in this project we will be using the Iris data set and deploying using API flask\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "te6yMrdauTwh",
        "outputId": "b2901a66-e548-4a18-d283-3748e21825ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-ec9bad00-3c4b-4888-999c-cfd071bb14f5\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-ec9bad00-3c4b-4888-999c-cfd071bb14f5\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving iris.csv to iris.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "df = pd.read_csv(io.BytesIO(uploaded['iris.csv']))\n",
        "# Dataset is now stored in a Pandas Dataframe"
      ],
      "metadata": {
        "id": "SJItvGVDutsl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "WWKDHKpTu7MJ",
        "outputId": "58f5b524-d8e2-4b89-da96-87058472ad0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal_length</th>\n",
              "      <th>sepal_width</th>\n",
              "      <th>petal_length</th>\n",
              "      <th>petal_width</th>\n",
              "      <th>species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>6.7</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>2.3</td>\n",
              "      <td>virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>6.3</td>\n",
              "      <td>2.5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.9</td>\n",
              "      <td>virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>6.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>6.2</td>\n",
              "      <td>3.4</td>\n",
              "      <td>5.4</td>\n",
              "      <td>2.3</td>\n",
              "      <td>virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>5.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.1</td>\n",
              "      <td>1.8</td>\n",
              "      <td>virginica</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>150 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     sepal_length  sepal_width  petal_length  petal_width    species\n",
              "0             5.1          3.5           1.4          0.2     setosa\n",
              "1             4.9          3.0           1.4          0.2     setosa\n",
              "2             4.7          3.2           1.3          0.2     setosa\n",
              "3             4.6          3.1           1.5          0.2     setosa\n",
              "4             5.0          3.6           1.4          0.2     setosa\n",
              "..            ...          ...           ...          ...        ...\n",
              "145           6.7          3.0           5.2          2.3  virginica\n",
              "146           6.3          2.5           5.0          1.9  virginica\n",
              "147           6.5          3.0           5.2          2.0  virginica\n",
              "148           6.2          3.4           5.4          2.3  virginica\n",
              "149           5.9          3.0           5.1          1.8  virginica\n",
              "\n",
              "[150 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop('species', axis = 1)"
      ],
      "metadata": {
        "id": "zkArGJS8u_CY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = df['species']"
      ],
      "metadata": {
        "id": "wHQxypSKvL-Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qBH4rA2LvN9v",
        "outputId": "3133cb14-65f7-4cc9-ece0-9a48a6a52a1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['setosa', 'versicolor', 'virginica'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelBinarizer\n",
        "encoder = LabelBinarizer()\n",
        "y = encoder.fit_transform(y)"
      ],
      "metadata": {
        "id": "O48MQ1z_vOZb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "metadata": {
        "id": "kSRt_ooOveQd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "r2DBpCUJvnJ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MinMaxScaler()\n",
        "scaler.fit(X_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V1BPaGwrvo8V",
        "outputId": "67777b4d-3c89-48ea-d18f-24cf8a8a6c13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MinMaxScaler()"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaled_X_train = scaler.transform(X_train)\n",
        "scaled_X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "frYlpB_YvwCj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense"
      ],
      "metadata": {
        "id": "kDOfIM8vvy1b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(units = 4, activation = 'relu', input_shape = [4,]))\n",
        "model.add(Dense(units = 3, activation = 'softmax'))\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "4wYFgUCYv02e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "early_stop = EarlyStopping(patience=10)"
      ],
      "metadata": {
        "id": "bXFVb06RwilH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x=scaled_X_train, \n",
        "          y=y_train, \n",
        "          epochs=300,\n",
        "          validation_data=(scaled_X_test, y_test), verbose=1 ,callbacks=[early_stop] )  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "huaIQRgVwyBm",
        "outputId": "ef4e9834-c145-4646-c247-05022719b564"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "4/4 [==============================] - 1s 61ms/step - loss: 1.1900 - accuracy: 0.2500 - val_loss: 1.1663 - val_accuracy: 0.3000\n",
            "Epoch 2/300\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.1840 - accuracy: 0.2583 - val_loss: 1.1614 - val_accuracy: 0.3000\n",
            "Epoch 3/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 1.1780 - accuracy: 0.2667 - val_loss: 1.1560 - val_accuracy: 0.3000\n",
            "Epoch 4/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.1716 - accuracy: 0.2500 - val_loss: 1.1508 - val_accuracy: 0.3000\n",
            "Epoch 5/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.1662 - accuracy: 0.2583 - val_loss: 1.1458 - val_accuracy: 0.3000\n",
            "Epoch 6/300\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.1608 - accuracy: 0.2667 - val_loss: 1.1407 - val_accuracy: 0.3000\n",
            "Epoch 7/300\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.1554 - accuracy: 0.2667 - val_loss: 1.1356 - val_accuracy: 0.3000\n",
            "Epoch 8/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 1.1499 - accuracy: 0.2750 - val_loss: 1.1306 - val_accuracy: 0.3000\n",
            "Epoch 9/300\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.1449 - accuracy: 0.2833 - val_loss: 1.1258 - val_accuracy: 0.3000\n",
            "Epoch 10/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 1.1393 - accuracy: 0.2833 - val_loss: 1.1209 - val_accuracy: 0.3000\n",
            "Epoch 11/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.1339 - accuracy: 0.3083 - val_loss: 1.1160 - val_accuracy: 0.3333\n",
            "Epoch 12/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.1287 - accuracy: 0.2917 - val_loss: 1.1113 - val_accuracy: 0.3333\n",
            "Epoch 13/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 1.1231 - accuracy: 0.2917 - val_loss: 1.1067 - val_accuracy: 0.3000\n",
            "Epoch 14/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.1178 - accuracy: 0.3000 - val_loss: 1.1019 - val_accuracy: 0.3333\n",
            "Epoch 15/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.1126 - accuracy: 0.2833 - val_loss: 1.0970 - val_accuracy: 0.3000\n",
            "Epoch 16/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 1.1073 - accuracy: 0.2667 - val_loss: 1.0921 - val_accuracy: 0.2667\n",
            "Epoch 17/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.1017 - accuracy: 0.2500 - val_loss: 1.0873 - val_accuracy: 0.2667\n",
            "Epoch 18/300\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.0967 - accuracy: 0.2417 - val_loss: 1.0827 - val_accuracy: 0.2333\n",
            "Epoch 19/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.0913 - accuracy: 0.2667 - val_loss: 1.0780 - val_accuracy: 0.2667\n",
            "Epoch 20/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 1.0857 - accuracy: 0.2750 - val_loss: 1.0733 - val_accuracy: 0.2667\n",
            "Epoch 21/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.0808 - accuracy: 0.2917 - val_loss: 1.0690 - val_accuracy: 0.2000\n",
            "Epoch 22/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.0758 - accuracy: 0.3083 - val_loss: 1.0644 - val_accuracy: 0.2000\n",
            "Epoch 23/300\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.0707 - accuracy: 0.3083 - val_loss: 1.0601 - val_accuracy: 0.2667\n",
            "Epoch 24/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.0660 - accuracy: 0.3167 - val_loss: 1.0556 - val_accuracy: 0.2333\n",
            "Epoch 25/300\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.0608 - accuracy: 0.3167 - val_loss: 1.0512 - val_accuracy: 0.2333\n",
            "Epoch 26/300\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.0563 - accuracy: 0.3167 - val_loss: 1.0470 - val_accuracy: 0.2333\n",
            "Epoch 27/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.0513 - accuracy: 0.3167 - val_loss: 1.0427 - val_accuracy: 0.2333\n",
            "Epoch 28/300\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.0465 - accuracy: 0.3333 - val_loss: 1.0384 - val_accuracy: 0.3000\n",
            "Epoch 29/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.0420 - accuracy: 0.3417 - val_loss: 1.0340 - val_accuracy: 0.3000\n",
            "Epoch 30/300\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.0373 - accuracy: 0.3500 - val_loss: 1.0296 - val_accuracy: 0.3000\n",
            "Epoch 31/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.0328 - accuracy: 0.3333 - val_loss: 1.0251 - val_accuracy: 0.3000\n",
            "Epoch 32/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.0280 - accuracy: 0.3417 - val_loss: 1.0207 - val_accuracy: 0.3000\n",
            "Epoch 33/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.0234 - accuracy: 0.3667 - val_loss: 1.0163 - val_accuracy: 0.3000\n",
            "Epoch 34/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 1.0187 - accuracy: 0.3917 - val_loss: 1.0117 - val_accuracy: 0.3333\n",
            "Epoch 35/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.0140 - accuracy: 0.4000 - val_loss: 1.0072 - val_accuracy: 0.3667\n",
            "Epoch 36/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.0093 - accuracy: 0.4250 - val_loss: 1.0024 - val_accuracy: 0.4000\n",
            "Epoch 37/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.0044 - accuracy: 0.4500 - val_loss: 0.9976 - val_accuracy: 0.4000\n",
            "Epoch 38/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.0001 - accuracy: 0.4917 - val_loss: 0.9930 - val_accuracy: 0.4667\n",
            "Epoch 39/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.9952 - accuracy: 0.5083 - val_loss: 0.9880 - val_accuracy: 0.4667\n",
            "Epoch 40/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.9904 - accuracy: 0.5250 - val_loss: 0.9832 - val_accuracy: 0.4667\n",
            "Epoch 41/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.9855 - accuracy: 0.5333 - val_loss: 0.9785 - val_accuracy: 0.5000\n",
            "Epoch 42/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.9807 - accuracy: 0.5583 - val_loss: 0.9738 - val_accuracy: 0.5000\n",
            "Epoch 43/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.9760 - accuracy: 0.5667 - val_loss: 0.9690 - val_accuracy: 0.5333\n",
            "Epoch 44/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.9714 - accuracy: 0.5750 - val_loss: 0.9642 - val_accuracy: 0.5333\n",
            "Epoch 45/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.9664 - accuracy: 0.5917 - val_loss: 0.9594 - val_accuracy: 0.5333\n",
            "Epoch 46/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.9616 - accuracy: 0.6000 - val_loss: 0.9548 - val_accuracy: 0.5333\n",
            "Epoch 47/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.9568 - accuracy: 0.6167 - val_loss: 0.9500 - val_accuracy: 0.5333\n",
            "Epoch 48/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.9519 - accuracy: 0.6250 - val_loss: 0.9451 - val_accuracy: 0.5333\n",
            "Epoch 49/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.9471 - accuracy: 0.6250 - val_loss: 0.9403 - val_accuracy: 0.5333\n",
            "Epoch 50/300\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.9421 - accuracy: 0.6333 - val_loss: 0.9353 - val_accuracy: 0.5333\n",
            "Epoch 51/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.9377 - accuracy: 0.6250 - val_loss: 0.9301 - val_accuracy: 0.5000\n",
            "Epoch 52/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.9325 - accuracy: 0.6167 - val_loss: 0.9254 - val_accuracy: 0.5000\n",
            "Epoch 53/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.9276 - accuracy: 0.6250 - val_loss: 0.9205 - val_accuracy: 0.5333\n",
            "Epoch 54/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.9228 - accuracy: 0.6250 - val_loss: 0.9156 - val_accuracy: 0.5333\n",
            "Epoch 55/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.9180 - accuracy: 0.6167 - val_loss: 0.9107 - val_accuracy: 0.5333\n",
            "Epoch 56/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.9132 - accuracy: 0.6083 - val_loss: 0.9057 - val_accuracy: 0.5667\n",
            "Epoch 57/300\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.9082 - accuracy: 0.6167 - val_loss: 0.9011 - val_accuracy: 0.5667\n",
            "Epoch 58/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.9035 - accuracy: 0.6250 - val_loss: 0.8964 - val_accuracy: 0.5667\n",
            "Epoch 59/300\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.8986 - accuracy: 0.6250 - val_loss: 0.8915 - val_accuracy: 0.5667\n",
            "Epoch 60/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.8939 - accuracy: 0.6167 - val_loss: 0.8869 - val_accuracy: 0.5667\n",
            "Epoch 61/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.8890 - accuracy: 0.6167 - val_loss: 0.8821 - val_accuracy: 0.5667\n",
            "Epoch 62/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.8841 - accuracy: 0.6167 - val_loss: 0.8772 - val_accuracy: 0.5667\n",
            "Epoch 63/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.8795 - accuracy: 0.6250 - val_loss: 0.8722 - val_accuracy: 0.5667\n",
            "Epoch 64/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.8745 - accuracy: 0.6417 - val_loss: 0.8674 - val_accuracy: 0.5667\n",
            "Epoch 65/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.8698 - accuracy: 0.6417 - val_loss: 0.8624 - val_accuracy: 0.5667\n",
            "Epoch 66/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.8649 - accuracy: 0.6417 - val_loss: 0.8574 - val_accuracy: 0.5333\n",
            "Epoch 67/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.8603 - accuracy: 0.6500 - val_loss: 0.8527 - val_accuracy: 0.5333\n",
            "Epoch 68/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.8555 - accuracy: 0.6583 - val_loss: 0.8476 - val_accuracy: 0.6000\n",
            "Epoch 69/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.8508 - accuracy: 0.6667 - val_loss: 0.8426 - val_accuracy: 0.6000\n",
            "Epoch 70/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.8462 - accuracy: 0.6583 - val_loss: 0.8377 - val_accuracy: 0.6000\n",
            "Epoch 71/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.8413 - accuracy: 0.6583 - val_loss: 0.8330 - val_accuracy: 0.6000\n",
            "Epoch 72/300\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.8367 - accuracy: 0.6667 - val_loss: 0.8282 - val_accuracy: 0.6000\n",
            "Epoch 73/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.8320 - accuracy: 0.6583 - val_loss: 0.8235 - val_accuracy: 0.6000\n",
            "Epoch 74/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.8274 - accuracy: 0.6583 - val_loss: 0.8188 - val_accuracy: 0.6333\n",
            "Epoch 75/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.8229 - accuracy: 0.6583 - val_loss: 0.8141 - val_accuracy: 0.6333\n",
            "Epoch 76/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.8183 - accuracy: 0.6667 - val_loss: 0.8094 - val_accuracy: 0.6667\n",
            "Epoch 77/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.8136 - accuracy: 0.6667 - val_loss: 0.8047 - val_accuracy: 0.6667\n",
            "Epoch 78/300\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.8091 - accuracy: 0.6667 - val_loss: 0.8000 - val_accuracy: 0.6667\n",
            "Epoch 79/300\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.8045 - accuracy: 0.6667 - val_loss: 0.7954 - val_accuracy: 0.7000\n",
            "Epoch 80/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.8003 - accuracy: 0.6750 - val_loss: 0.7905 - val_accuracy: 0.7000\n",
            "Epoch 81/300\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.7958 - accuracy: 0.6750 - val_loss: 0.7858 - val_accuracy: 0.7333\n",
            "Epoch 82/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.7913 - accuracy: 0.6750 - val_loss: 0.7815 - val_accuracy: 0.7333\n",
            "Epoch 83/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.7869 - accuracy: 0.6750 - val_loss: 0.7770 - val_accuracy: 0.7333\n",
            "Epoch 84/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.7828 - accuracy: 0.6833 - val_loss: 0.7724 - val_accuracy: 0.7333\n",
            "Epoch 85/300\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.7784 - accuracy: 0.6833 - val_loss: 0.7682 - val_accuracy: 0.7333\n",
            "Epoch 86/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.7741 - accuracy: 0.6833 - val_loss: 0.7640 - val_accuracy: 0.7667\n",
            "Epoch 87/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.7698 - accuracy: 0.6833 - val_loss: 0.7600 - val_accuracy: 0.7667\n",
            "Epoch 88/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.7657 - accuracy: 0.6833 - val_loss: 0.7559 - val_accuracy: 0.7667\n",
            "Epoch 89/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.7617 - accuracy: 0.6833 - val_loss: 0.7514 - val_accuracy: 0.7667\n",
            "Epoch 90/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.7575 - accuracy: 0.6833 - val_loss: 0.7470 - val_accuracy: 0.7333\n",
            "Epoch 91/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.7534 - accuracy: 0.6833 - val_loss: 0.7428 - val_accuracy: 0.7333\n",
            "Epoch 92/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.7493 - accuracy: 0.6833 - val_loss: 0.7387 - val_accuracy: 0.7333\n",
            "Epoch 93/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.7454 - accuracy: 0.6833 - val_loss: 0.7345 - val_accuracy: 0.7333\n",
            "Epoch 94/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.7413 - accuracy: 0.7000 - val_loss: 0.7304 - val_accuracy: 0.7333\n",
            "Epoch 95/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.7374 - accuracy: 0.7000 - val_loss: 0.7263 - val_accuracy: 0.7333\n",
            "Epoch 96/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.7335 - accuracy: 0.7000 - val_loss: 0.7223 - val_accuracy: 0.7333\n",
            "Epoch 97/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.7297 - accuracy: 0.7083 - val_loss: 0.7181 - val_accuracy: 0.7333\n",
            "Epoch 98/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.7257 - accuracy: 0.7167 - val_loss: 0.7141 - val_accuracy: 0.7333\n",
            "Epoch 99/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.7220 - accuracy: 0.7167 - val_loss: 0.7102 - val_accuracy: 0.7333\n",
            "Epoch 100/300\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.7181 - accuracy: 0.7167 - val_loss: 0.7064 - val_accuracy: 0.7333\n",
            "Epoch 101/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.7143 - accuracy: 0.7167 - val_loss: 0.7028 - val_accuracy: 0.7333\n",
            "Epoch 102/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.7107 - accuracy: 0.7083 - val_loss: 0.6990 - val_accuracy: 0.7333\n",
            "Epoch 103/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.7071 - accuracy: 0.7083 - val_loss: 0.6952 - val_accuracy: 0.7333\n",
            "Epoch 104/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.7033 - accuracy: 0.7083 - val_loss: 0.6918 - val_accuracy: 0.7333\n",
            "Epoch 105/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6998 - accuracy: 0.7083 - val_loss: 0.6882 - val_accuracy: 0.7333\n",
            "Epoch 106/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6963 - accuracy: 0.7083 - val_loss: 0.6848 - val_accuracy: 0.7667\n",
            "Epoch 107/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6928 - accuracy: 0.7083 - val_loss: 0.6812 - val_accuracy: 0.7667\n",
            "Epoch 108/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6893 - accuracy: 0.7083 - val_loss: 0.6776 - val_accuracy: 0.7667\n",
            "Epoch 109/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6860 - accuracy: 0.7167 - val_loss: 0.6742 - val_accuracy: 0.7667\n",
            "Epoch 110/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6825 - accuracy: 0.7250 - val_loss: 0.6707 - val_accuracy: 0.7333\n",
            "Epoch 111/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6793 - accuracy: 0.7250 - val_loss: 0.6669 - val_accuracy: 0.7333\n",
            "Epoch 112/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6759 - accuracy: 0.7250 - val_loss: 0.6634 - val_accuracy: 0.7333\n",
            "Epoch 113/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6727 - accuracy: 0.7333 - val_loss: 0.6599 - val_accuracy: 0.7333\n",
            "Epoch 114/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6693 - accuracy: 0.7333 - val_loss: 0.6566 - val_accuracy: 0.7333\n",
            "Epoch 115/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6662 - accuracy: 0.7333 - val_loss: 0.6532 - val_accuracy: 0.7333\n",
            "Epoch 116/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6631 - accuracy: 0.7333 - val_loss: 0.6499 - val_accuracy: 0.7333\n",
            "Epoch 117/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6599 - accuracy: 0.7333 - val_loss: 0.6466 - val_accuracy: 0.7333\n",
            "Epoch 118/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6569 - accuracy: 0.7250 - val_loss: 0.6433 - val_accuracy: 0.7333\n",
            "Epoch 119/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6538 - accuracy: 0.7250 - val_loss: 0.6400 - val_accuracy: 0.7333\n",
            "Epoch 120/300\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.6510 - accuracy: 0.7250 - val_loss: 0.6367 - val_accuracy: 0.7333\n",
            "Epoch 121/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6478 - accuracy: 0.7250 - val_loss: 0.6337 - val_accuracy: 0.7333\n",
            "Epoch 122/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6450 - accuracy: 0.7250 - val_loss: 0.6306 - val_accuracy: 0.7333\n",
            "Epoch 123/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6420 - accuracy: 0.7250 - val_loss: 0.6275 - val_accuracy: 0.7333\n",
            "Epoch 124/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6391 - accuracy: 0.7333 - val_loss: 0.6247 - val_accuracy: 0.7333\n",
            "Epoch 125/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6363 - accuracy: 0.7333 - val_loss: 0.6218 - val_accuracy: 0.7333\n",
            "Epoch 126/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6334 - accuracy: 0.7417 - val_loss: 0.6190 - val_accuracy: 0.7333\n",
            "Epoch 127/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6306 - accuracy: 0.7417 - val_loss: 0.6161 - val_accuracy: 0.7333\n",
            "Epoch 128/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6279 - accuracy: 0.7417 - val_loss: 0.6132 - val_accuracy: 0.7333\n",
            "Epoch 129/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6251 - accuracy: 0.7417 - val_loss: 0.6103 - val_accuracy: 0.7333\n",
            "Epoch 130/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6224 - accuracy: 0.7417 - val_loss: 0.6076 - val_accuracy: 0.7333\n",
            "Epoch 131/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6197 - accuracy: 0.7417 - val_loss: 0.6047 - val_accuracy: 0.7333\n",
            "Epoch 132/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6170 - accuracy: 0.7417 - val_loss: 0.6020 - val_accuracy: 0.7333\n",
            "Epoch 133/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6146 - accuracy: 0.7417 - val_loss: 0.5994 - val_accuracy: 0.7333\n",
            "Epoch 134/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6118 - accuracy: 0.7417 - val_loss: 0.5965 - val_accuracy: 0.7333\n",
            "Epoch 135/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6093 - accuracy: 0.7417 - val_loss: 0.5939 - val_accuracy: 0.7333\n",
            "Epoch 136/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6067 - accuracy: 0.7417 - val_loss: 0.5912 - val_accuracy: 0.7333\n",
            "Epoch 137/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6041 - accuracy: 0.7417 - val_loss: 0.5883 - val_accuracy: 0.7333\n",
            "Epoch 138/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6015 - accuracy: 0.7417 - val_loss: 0.5858 - val_accuracy: 0.7333\n",
            "Epoch 139/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5990 - accuracy: 0.7417 - val_loss: 0.5831 - val_accuracy: 0.7333\n",
            "Epoch 140/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5964 - accuracy: 0.7417 - val_loss: 0.5804 - val_accuracy: 0.7333\n",
            "Epoch 141/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5939 - accuracy: 0.7500 - val_loss: 0.5776 - val_accuracy: 0.7333\n",
            "Epoch 142/300\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.5914 - accuracy: 0.7500 - val_loss: 0.5750 - val_accuracy: 0.7333\n",
            "Epoch 143/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5888 - accuracy: 0.7500 - val_loss: 0.5723 - val_accuracy: 0.7333\n",
            "Epoch 144/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5863 - accuracy: 0.7500 - val_loss: 0.5698 - val_accuracy: 0.7333\n",
            "Epoch 145/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5839 - accuracy: 0.7500 - val_loss: 0.5673 - val_accuracy: 0.7333\n",
            "Epoch 146/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5814 - accuracy: 0.7500 - val_loss: 0.5650 - val_accuracy: 0.7333\n",
            "Epoch 147/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5790 - accuracy: 0.7500 - val_loss: 0.5625 - val_accuracy: 0.7333\n",
            "Epoch 148/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5766 - accuracy: 0.7583 - val_loss: 0.5601 - val_accuracy: 0.7667\n",
            "Epoch 149/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.5743 - accuracy: 0.7583 - val_loss: 0.5578 - val_accuracy: 0.7667\n",
            "Epoch 150/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5719 - accuracy: 0.7583 - val_loss: 0.5553 - val_accuracy: 0.7667\n",
            "Epoch 151/300\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.5696 - accuracy: 0.7583 - val_loss: 0.5529 - val_accuracy: 0.7667\n",
            "Epoch 152/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5675 - accuracy: 0.7583 - val_loss: 0.5505 - val_accuracy: 0.7667\n",
            "Epoch 153/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5652 - accuracy: 0.7583 - val_loss: 0.5482 - val_accuracy: 0.7667\n",
            "Epoch 154/300\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.5629 - accuracy: 0.7583 - val_loss: 0.5460 - val_accuracy: 0.7667\n",
            "Epoch 155/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5607 - accuracy: 0.7667 - val_loss: 0.5439 - val_accuracy: 0.7667\n",
            "Epoch 156/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5585 - accuracy: 0.7667 - val_loss: 0.5416 - val_accuracy: 0.7667\n",
            "Epoch 157/300\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.5563 - accuracy: 0.7667 - val_loss: 0.5394 - val_accuracy: 0.7667\n",
            "Epoch 158/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5542 - accuracy: 0.7667 - val_loss: 0.5373 - val_accuracy: 0.7667\n",
            "Epoch 159/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5520 - accuracy: 0.7667 - val_loss: 0.5350 - val_accuracy: 0.8000\n",
            "Epoch 160/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5498 - accuracy: 0.7750 - val_loss: 0.5327 - val_accuracy: 0.8000\n",
            "Epoch 161/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5477 - accuracy: 0.7750 - val_loss: 0.5307 - val_accuracy: 0.8000\n",
            "Epoch 162/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5455 - accuracy: 0.7750 - val_loss: 0.5284 - val_accuracy: 0.8000\n",
            "Epoch 163/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5434 - accuracy: 0.7750 - val_loss: 0.5262 - val_accuracy: 0.8000\n",
            "Epoch 164/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5413 - accuracy: 0.7750 - val_loss: 0.5241 - val_accuracy: 0.8000\n",
            "Epoch 165/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5392 - accuracy: 0.7750 - val_loss: 0.5220 - val_accuracy: 0.8000\n",
            "Epoch 166/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5371 - accuracy: 0.7833 - val_loss: 0.5200 - val_accuracy: 0.8000\n",
            "Epoch 167/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5351 - accuracy: 0.7833 - val_loss: 0.5179 - val_accuracy: 0.8000\n",
            "Epoch 168/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5332 - accuracy: 0.7833 - val_loss: 0.5158 - val_accuracy: 0.8000\n",
            "Epoch 169/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5313 - accuracy: 0.7833 - val_loss: 0.5137 - val_accuracy: 0.8000\n",
            "Epoch 170/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5295 - accuracy: 0.7833 - val_loss: 0.5118 - val_accuracy: 0.8000\n",
            "Epoch 171/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5276 - accuracy: 0.7833 - val_loss: 0.5100 - val_accuracy: 0.8000\n",
            "Epoch 172/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5258 - accuracy: 0.7833 - val_loss: 0.5080 - val_accuracy: 0.8000\n",
            "Epoch 173/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5240 - accuracy: 0.7833 - val_loss: 0.5061 - val_accuracy: 0.8000\n",
            "Epoch 174/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5222 - accuracy: 0.7833 - val_loss: 0.5042 - val_accuracy: 0.8000\n",
            "Epoch 175/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5204 - accuracy: 0.7833 - val_loss: 0.5024 - val_accuracy: 0.8000\n",
            "Epoch 176/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5187 - accuracy: 0.7833 - val_loss: 0.5007 - val_accuracy: 0.8000\n",
            "Epoch 177/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5170 - accuracy: 0.7833 - val_loss: 0.4989 - val_accuracy: 0.8000\n",
            "Epoch 178/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5152 - accuracy: 0.7917 - val_loss: 0.4971 - val_accuracy: 0.8000\n",
            "Epoch 179/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5135 - accuracy: 0.7917 - val_loss: 0.4954 - val_accuracy: 0.8000\n",
            "Epoch 180/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5120 - accuracy: 0.7917 - val_loss: 0.4937 - val_accuracy: 0.8000\n",
            "Epoch 181/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5101 - accuracy: 0.7917 - val_loss: 0.4919 - val_accuracy: 0.8000\n",
            "Epoch 182/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5086 - accuracy: 0.7917 - val_loss: 0.4900 - val_accuracy: 0.8000\n",
            "Epoch 183/300\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.5068 - accuracy: 0.7917 - val_loss: 0.4883 - val_accuracy: 0.8000\n",
            "Epoch 184/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5052 - accuracy: 0.7917 - val_loss: 0.4866 - val_accuracy: 0.8000\n",
            "Epoch 185/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5037 - accuracy: 0.7917 - val_loss: 0.4851 - val_accuracy: 0.8000\n",
            "Epoch 186/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5022 - accuracy: 0.7917 - val_loss: 0.4835 - val_accuracy: 0.8333\n",
            "Epoch 187/300\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.5005 - accuracy: 0.7917 - val_loss: 0.4818 - val_accuracy: 0.8333\n",
            "Epoch 188/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4990 - accuracy: 0.7917 - val_loss: 0.4801 - val_accuracy: 0.8333\n",
            "Epoch 189/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4974 - accuracy: 0.7917 - val_loss: 0.4784 - val_accuracy: 0.8333\n",
            "Epoch 190/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4959 - accuracy: 0.7917 - val_loss: 0.4767 - val_accuracy: 0.8333\n",
            "Epoch 191/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4944 - accuracy: 0.7917 - val_loss: 0.4751 - val_accuracy: 0.8333\n",
            "Epoch 192/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4929 - accuracy: 0.7917 - val_loss: 0.4734 - val_accuracy: 0.8333\n",
            "Epoch 193/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4914 - accuracy: 0.7917 - val_loss: 0.4719 - val_accuracy: 0.8333\n",
            "Epoch 194/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4901 - accuracy: 0.7917 - val_loss: 0.4702 - val_accuracy: 0.8333\n",
            "Epoch 195/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4886 - accuracy: 0.7917 - val_loss: 0.4687 - val_accuracy: 0.8333\n",
            "Epoch 196/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4870 - accuracy: 0.8000 - val_loss: 0.4672 - val_accuracy: 0.8333\n",
            "Epoch 197/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4857 - accuracy: 0.8000 - val_loss: 0.4656 - val_accuracy: 0.8333\n",
            "Epoch 198/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4843 - accuracy: 0.8000 - val_loss: 0.4641 - val_accuracy: 0.8333\n",
            "Epoch 199/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4829 - accuracy: 0.8000 - val_loss: 0.4626 - val_accuracy: 0.8333\n",
            "Epoch 200/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4815 - accuracy: 0.8000 - val_loss: 0.4612 - val_accuracy: 0.8333\n",
            "Epoch 201/300\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.4801 - accuracy: 0.8000 - val_loss: 0.4598 - val_accuracy: 0.8333\n",
            "Epoch 202/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4787 - accuracy: 0.8000 - val_loss: 0.4585 - val_accuracy: 0.8333\n",
            "Epoch 203/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4774 - accuracy: 0.8083 - val_loss: 0.4570 - val_accuracy: 0.8333\n",
            "Epoch 204/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4760 - accuracy: 0.8083 - val_loss: 0.4556 - val_accuracy: 0.8333\n",
            "Epoch 205/300\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.4746 - accuracy: 0.8083 - val_loss: 0.4543 - val_accuracy: 0.8333\n",
            "Epoch 206/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4733 - accuracy: 0.8167 - val_loss: 0.4531 - val_accuracy: 0.8667\n",
            "Epoch 207/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4720 - accuracy: 0.8167 - val_loss: 0.4517 - val_accuracy: 0.8667\n",
            "Epoch 208/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4707 - accuracy: 0.8250 - val_loss: 0.4503 - val_accuracy: 0.8667\n",
            "Epoch 209/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4694 - accuracy: 0.8333 - val_loss: 0.4489 - val_accuracy: 0.8667\n",
            "Epoch 210/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4681 - accuracy: 0.8333 - val_loss: 0.4475 - val_accuracy: 0.8667\n",
            "Epoch 211/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4669 - accuracy: 0.8333 - val_loss: 0.4460 - val_accuracy: 0.8667\n",
            "Epoch 212/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4656 - accuracy: 0.8333 - val_loss: 0.4446 - val_accuracy: 0.8667\n",
            "Epoch 213/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4643 - accuracy: 0.8333 - val_loss: 0.4434 - val_accuracy: 0.8667\n",
            "Epoch 214/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4631 - accuracy: 0.8333 - val_loss: 0.4421 - val_accuracy: 0.8667\n",
            "Epoch 215/300\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.4618 - accuracy: 0.8333 - val_loss: 0.4407 - val_accuracy: 0.8667\n",
            "Epoch 216/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4607 - accuracy: 0.8333 - val_loss: 0.4396 - val_accuracy: 0.8667\n",
            "Epoch 217/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4594 - accuracy: 0.8333 - val_loss: 0.4383 - val_accuracy: 0.8667\n",
            "Epoch 218/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4582 - accuracy: 0.8333 - val_loss: 0.4369 - val_accuracy: 0.8667\n",
            "Epoch 219/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4570 - accuracy: 0.8333 - val_loss: 0.4356 - val_accuracy: 0.8667\n",
            "Epoch 220/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4557 - accuracy: 0.8333 - val_loss: 0.4343 - val_accuracy: 0.8667\n",
            "Epoch 221/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4546 - accuracy: 0.8333 - val_loss: 0.4330 - val_accuracy: 0.8667\n",
            "Epoch 222/300\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.4533 - accuracy: 0.8333 - val_loss: 0.4319 - val_accuracy: 0.8667\n",
            "Epoch 223/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4523 - accuracy: 0.8333 - val_loss: 0.4308 - val_accuracy: 0.8667\n",
            "Epoch 224/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4510 - accuracy: 0.8417 - val_loss: 0.4295 - val_accuracy: 0.8667\n",
            "Epoch 225/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4499 - accuracy: 0.8500 - val_loss: 0.4284 - val_accuracy: 0.8667\n",
            "Epoch 226/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4487 - accuracy: 0.8500 - val_loss: 0.4270 - val_accuracy: 0.8667\n",
            "Epoch 227/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4475 - accuracy: 0.8500 - val_loss: 0.4258 - val_accuracy: 0.8667\n",
            "Epoch 228/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4464 - accuracy: 0.8500 - val_loss: 0.4245 - val_accuracy: 0.8667\n",
            "Epoch 229/300\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.4454 - accuracy: 0.8500 - val_loss: 0.4232 - val_accuracy: 0.8667\n",
            "Epoch 230/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4442 - accuracy: 0.8500 - val_loss: 0.4220 - val_accuracy: 0.8667\n",
            "Epoch 231/300\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.4431 - accuracy: 0.8583 - val_loss: 0.4209 - val_accuracy: 0.8667\n",
            "Epoch 232/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4419 - accuracy: 0.8583 - val_loss: 0.4197 - val_accuracy: 0.8667\n",
            "Epoch 233/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4408 - accuracy: 0.8583 - val_loss: 0.4185 - val_accuracy: 0.8667\n",
            "Epoch 234/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4397 - accuracy: 0.8583 - val_loss: 0.4172 - val_accuracy: 0.8667\n",
            "Epoch 235/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4386 - accuracy: 0.8583 - val_loss: 0.4161 - val_accuracy: 0.8667\n",
            "Epoch 236/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4376 - accuracy: 0.8583 - val_loss: 0.4148 - val_accuracy: 0.8667\n",
            "Epoch 237/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4365 - accuracy: 0.8583 - val_loss: 0.4137 - val_accuracy: 0.8667\n",
            "Epoch 238/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4354 - accuracy: 0.8667 - val_loss: 0.4126 - val_accuracy: 0.9000\n",
            "Epoch 239/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4343 - accuracy: 0.8667 - val_loss: 0.4115 - val_accuracy: 0.9000\n",
            "Epoch 240/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4332 - accuracy: 0.8667 - val_loss: 0.4104 - val_accuracy: 0.9000\n",
            "Epoch 241/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4322 - accuracy: 0.8667 - val_loss: 0.4093 - val_accuracy: 0.9000\n",
            "Epoch 242/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4311 - accuracy: 0.8667 - val_loss: 0.4082 - val_accuracy: 0.9000\n",
            "Epoch 243/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4301 - accuracy: 0.8667 - val_loss: 0.4070 - val_accuracy: 0.9000\n",
            "Epoch 244/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4290 - accuracy: 0.8667 - val_loss: 0.4058 - val_accuracy: 0.9000\n",
            "Epoch 245/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4280 - accuracy: 0.8667 - val_loss: 0.4047 - val_accuracy: 0.9000\n",
            "Epoch 246/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4270 - accuracy: 0.8667 - val_loss: 0.4035 - val_accuracy: 0.9000\n",
            "Epoch 247/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4259 - accuracy: 0.8667 - val_loss: 0.4024 - val_accuracy: 0.9000\n",
            "Epoch 248/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4249 - accuracy: 0.8667 - val_loss: 0.4012 - val_accuracy: 0.9000\n",
            "Epoch 249/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4239 - accuracy: 0.8667 - val_loss: 0.4002 - val_accuracy: 0.9000\n",
            "Epoch 250/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4230 - accuracy: 0.8667 - val_loss: 0.3992 - val_accuracy: 0.9000\n",
            "Epoch 251/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4223 - accuracy: 0.8750 - val_loss: 0.3983 - val_accuracy: 0.9000\n",
            "Epoch 252/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4208 - accuracy: 0.8833 - val_loss: 0.3971 - val_accuracy: 0.9000\n",
            "Epoch 253/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4199 - accuracy: 0.8833 - val_loss: 0.3961 - val_accuracy: 0.9333\n",
            "Epoch 254/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4189 - accuracy: 0.8833 - val_loss: 0.3950 - val_accuracy: 0.9333\n",
            "Epoch 255/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4179 - accuracy: 0.8833 - val_loss: 0.3939 - val_accuracy: 0.9333\n",
            "Epoch 256/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4169 - accuracy: 0.8833 - val_loss: 0.3928 - val_accuracy: 0.9333\n",
            "Epoch 257/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4159 - accuracy: 0.8833 - val_loss: 0.3917 - val_accuracy: 0.9333\n",
            "Epoch 258/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4150 - accuracy: 0.8833 - val_loss: 0.3907 - val_accuracy: 0.9333\n",
            "Epoch 259/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4140 - accuracy: 0.8833 - val_loss: 0.3896 - val_accuracy: 0.9333\n",
            "Epoch 260/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4130 - accuracy: 0.8833 - val_loss: 0.3886 - val_accuracy: 0.9333\n",
            "Epoch 261/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4121 - accuracy: 0.8833 - val_loss: 0.3874 - val_accuracy: 0.9333\n",
            "Epoch 262/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4111 - accuracy: 0.8833 - val_loss: 0.3864 - val_accuracy: 0.9333\n",
            "Epoch 263/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4101 - accuracy: 0.8833 - val_loss: 0.3853 - val_accuracy: 0.9333\n",
            "Epoch 264/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4092 - accuracy: 0.8833 - val_loss: 0.3843 - val_accuracy: 0.9333\n",
            "Epoch 265/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4082 - accuracy: 0.8833 - val_loss: 0.3833 - val_accuracy: 0.9333\n",
            "Epoch 266/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4074 - accuracy: 0.8833 - val_loss: 0.3822 - val_accuracy: 0.9333\n",
            "Epoch 267/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4063 - accuracy: 0.8833 - val_loss: 0.3812 - val_accuracy: 0.9333\n",
            "Epoch 268/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4054 - accuracy: 0.8833 - val_loss: 0.3803 - val_accuracy: 0.9333\n",
            "Epoch 269/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4044 - accuracy: 0.8833 - val_loss: 0.3793 - val_accuracy: 0.9333\n",
            "Epoch 270/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4037 - accuracy: 0.8833 - val_loss: 0.3784 - val_accuracy: 0.9333\n",
            "Epoch 271/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4026 - accuracy: 0.8833 - val_loss: 0.3774 - val_accuracy: 0.9333\n",
            "Epoch 272/300\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4018 - accuracy: 0.8833 - val_loss: 0.3765 - val_accuracy: 0.9333\n",
            "Epoch 273/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4007 - accuracy: 0.8833 - val_loss: 0.3754 - val_accuracy: 0.9333\n",
            "Epoch 274/300\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.3998 - accuracy: 0.8833 - val_loss: 0.3744 - val_accuracy: 0.9333\n",
            "Epoch 275/300\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.3990 - accuracy: 0.8833 - val_loss: 0.3734 - val_accuracy: 0.9333\n",
            "Epoch 276/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3980 - accuracy: 0.8833 - val_loss: 0.3723 - val_accuracy: 0.9333\n",
            "Epoch 277/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3971 - accuracy: 0.8833 - val_loss: 0.3713 - val_accuracy: 0.9333\n",
            "Epoch 278/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3962 - accuracy: 0.8833 - val_loss: 0.3702 - val_accuracy: 0.9333\n",
            "Epoch 279/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3952 - accuracy: 0.8833 - val_loss: 0.3692 - val_accuracy: 0.9333\n",
            "Epoch 280/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3944 - accuracy: 0.8833 - val_loss: 0.3683 - val_accuracy: 0.9333\n",
            "Epoch 281/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3935 - accuracy: 0.8833 - val_loss: 0.3673 - val_accuracy: 0.9333\n",
            "Epoch 282/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3926 - accuracy: 0.8833 - val_loss: 0.3663 - val_accuracy: 0.9333\n",
            "Epoch 283/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3917 - accuracy: 0.8833 - val_loss: 0.3654 - val_accuracy: 0.9333\n",
            "Epoch 284/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.3907 - accuracy: 0.8833 - val_loss: 0.3645 - val_accuracy: 0.9333\n",
            "Epoch 285/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3899 - accuracy: 0.8833 - val_loss: 0.3636 - val_accuracy: 0.9333\n",
            "Epoch 286/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3890 - accuracy: 0.8833 - val_loss: 0.3626 - val_accuracy: 0.9333\n",
            "Epoch 287/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3881 - accuracy: 0.8833 - val_loss: 0.3617 - val_accuracy: 0.9333\n",
            "Epoch 288/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.3873 - accuracy: 0.8917 - val_loss: 0.3608 - val_accuracy: 0.9333\n",
            "Epoch 289/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.3863 - accuracy: 0.8917 - val_loss: 0.3599 - val_accuracy: 0.9333\n",
            "Epoch 290/300\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3855 - accuracy: 0.8917 - val_loss: 0.3588 - val_accuracy: 0.9333\n",
            "Epoch 291/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3846 - accuracy: 0.8917 - val_loss: 0.3579 - val_accuracy: 0.9333\n",
            "Epoch 292/300\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.3837 - accuracy: 0.8917 - val_loss: 0.3570 - val_accuracy: 0.9333\n",
            "Epoch 293/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3828 - accuracy: 0.8917 - val_loss: 0.3560 - val_accuracy: 0.9333\n",
            "Epoch 294/300\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.3820 - accuracy: 0.8917 - val_loss: 0.3551 - val_accuracy: 0.9333\n",
            "Epoch 295/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3811 - accuracy: 0.8917 - val_loss: 0.3541 - val_accuracy: 0.9333\n",
            "Epoch 296/300\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.3802 - accuracy: 0.8917 - val_loss: 0.3532 - val_accuracy: 0.9333\n",
            "Epoch 297/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3793 - accuracy: 0.8917 - val_loss: 0.3523 - val_accuracy: 0.9333\n",
            "Epoch 298/300\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.3784 - accuracy: 0.8917 - val_loss: 0.3513 - val_accuracy: 0.9333\n",
            "Epoch 299/300\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3776 - accuracy: 0.8917 - val_loss: 0.3504 - val_accuracy: 0.9333\n",
            "Epoch 300/300\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3767 - accuracy: 0.8917 - val_loss: 0.3494 - val_accuracy: 0.9333\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0361470150>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = pd.DataFrame(model.history.history)\n",
        "metrics.plot()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "65m9OwF-wykZ",
        "outputId": "cceff008-95f7-4e7a-df68-0dacbb73b521"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f0360e90490>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(scaled_X_test,y_test,verbose=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p6Or5nMAw74Y",
        "outputId": "00218d62-026a-41a6-8a30-321e33c54109"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.34944862127304077, 0.9333333373069763]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ready for deployment from here with 90% validation\n",
        "#we are doing to now make the model again and train with all the data"
      ],
      "metadata": {
        "id": "qbo9oAlyxnso"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = len(metrics)"
      ],
      "metadata": {
        "id": "yEnOVfx3x3zy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaled_X =  scaler.fit_transform(X)"
      ],
      "metadata": {
        "id": "WsSSnv_Fx44W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential() #make the model with all the data for training\n",
        "model.add(Dense(units=4,activation='relu'))\n",
        "\n",
        "# Last layer for multi-class classification of 3 species\n",
        "model.add(Dense(units=3,activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "Gfr6SY91x9K3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(scaled_X, y,epochs = epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S2Ex4uAXyKr-",
        "outputId": "90cfa8d0-d81e-4661-e913-5ea78f91f8cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "5/5 [==============================] - 1s 4ms/step - loss: 1.1405 - accuracy: 0.3333\n",
            "Epoch 2/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.1349 - accuracy: 0.3333\n",
            "Epoch 3/300\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 1.1296 - accuracy: 0.3333\n",
            "Epoch 4/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.1246 - accuracy: 0.3333\n",
            "Epoch 5/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.1198 - accuracy: 0.3333\n",
            "Epoch 6/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.1145 - accuracy: 0.3333\n",
            "Epoch 7/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.1097 - accuracy: 0.3333\n",
            "Epoch 8/300\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 1.1046 - accuracy: 0.3333\n",
            "Epoch 9/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.0997 - accuracy: 0.3333\n",
            "Epoch 10/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.0950 - accuracy: 0.3333\n",
            "Epoch 11/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0899 - accuracy: 0.3333\n",
            "Epoch 12/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.0853 - accuracy: 0.3400\n",
            "Epoch 13/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0802 - accuracy: 0.3400\n",
            "Epoch 14/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.0760 - accuracy: 0.3400\n",
            "Epoch 15/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0720 - accuracy: 0.3400\n",
            "Epoch 16/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0679 - accuracy: 0.3400\n",
            "Epoch 17/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0643 - accuracy: 0.3400\n",
            "Epoch 18/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0596 - accuracy: 0.3400\n",
            "Epoch 19/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0558 - accuracy: 0.3400\n",
            "Epoch 20/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0518 - accuracy: 0.3400\n",
            "Epoch 21/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0478 - accuracy: 0.3400\n",
            "Epoch 22/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0436 - accuracy: 0.3400\n",
            "Epoch 23/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.0394 - accuracy: 0.3467\n",
            "Epoch 24/300\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 1.0355 - accuracy: 0.3533\n",
            "Epoch 25/300\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 1.0313 - accuracy: 0.3600\n",
            "Epoch 26/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0270 - accuracy: 0.3667\n",
            "Epoch 27/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0229 - accuracy: 0.3733\n",
            "Epoch 28/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.0187 - accuracy: 0.3867\n",
            "Epoch 29/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0145 - accuracy: 0.4133\n",
            "Epoch 30/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0100 - accuracy: 0.4333\n",
            "Epoch 31/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0057 - accuracy: 0.4400\n",
            "Epoch 32/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.0014 - accuracy: 0.4400\n",
            "Epoch 33/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9968 - accuracy: 0.4667\n",
            "Epoch 34/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9923 - accuracy: 0.4733\n",
            "Epoch 35/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9879 - accuracy: 0.4933\n",
            "Epoch 36/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9831 - accuracy: 0.5067\n",
            "Epoch 37/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9786 - accuracy: 0.5200\n",
            "Epoch 38/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9739 - accuracy: 0.5467\n",
            "Epoch 39/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9691 - accuracy: 0.5600\n",
            "Epoch 40/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9643 - accuracy: 0.5800\n",
            "Epoch 41/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9594 - accuracy: 0.5933\n",
            "Epoch 42/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9544 - accuracy: 0.6133\n",
            "Epoch 43/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9496 - accuracy: 0.6267\n",
            "Epoch 44/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9445 - accuracy: 0.6267\n",
            "Epoch 45/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9394 - accuracy: 0.6267\n",
            "Epoch 46/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.9342 - accuracy: 0.6533\n",
            "Epoch 47/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9291 - accuracy: 0.6600\n",
            "Epoch 48/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.9238 - accuracy: 0.6600\n",
            "Epoch 49/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9185 - accuracy: 0.6600\n",
            "Epoch 50/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9130 - accuracy: 0.6600\n",
            "Epoch 51/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9076 - accuracy: 0.6600\n",
            "Epoch 52/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9021 - accuracy: 0.6600\n",
            "Epoch 53/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8966 - accuracy: 0.6667\n",
            "Epoch 54/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8910 - accuracy: 0.6667\n",
            "Epoch 55/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8853 - accuracy: 0.6667\n",
            "Epoch 56/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8798 - accuracy: 0.6667\n",
            "Epoch 57/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8741 - accuracy: 0.6667\n",
            "Epoch 58/300\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.8682 - accuracy: 0.6667\n",
            "Epoch 59/300\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.8626 - accuracy: 0.6667\n",
            "Epoch 60/300\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.8568 - accuracy: 0.6667\n",
            "Epoch 61/300\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.8510 - accuracy: 0.6733\n",
            "Epoch 62/300\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.8454 - accuracy: 0.6733\n",
            "Epoch 63/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8396 - accuracy: 0.6733\n",
            "Epoch 64/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8339 - accuracy: 0.6733\n",
            "Epoch 65/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8282 - accuracy: 0.6733\n",
            "Epoch 66/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8226 - accuracy: 0.6733\n",
            "Epoch 67/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8168 - accuracy: 0.6733\n",
            "Epoch 68/300\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.8114 - accuracy: 0.6733\n",
            "Epoch 69/300\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.8056 - accuracy: 0.6733\n",
            "Epoch 70/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.8001 - accuracy: 0.6733\n",
            "Epoch 71/300\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.7946 - accuracy: 0.6733\n",
            "Epoch 72/300\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.7890 - accuracy: 0.6733\n",
            "Epoch 73/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7835 - accuracy: 0.6733\n",
            "Epoch 74/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7781 - accuracy: 0.6800\n",
            "Epoch 75/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7725 - accuracy: 0.6800\n",
            "Epoch 76/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7671 - accuracy: 0.6800\n",
            "Epoch 77/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7617 - accuracy: 0.6800\n",
            "Epoch 78/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7563 - accuracy: 0.6867\n",
            "Epoch 79/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7510 - accuracy: 0.6867\n",
            "Epoch 80/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7457 - accuracy: 0.6867\n",
            "Epoch 81/300\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.7404 - accuracy: 0.6867\n",
            "Epoch 82/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7352 - accuracy: 0.6867\n",
            "Epoch 83/300\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.7301 - accuracy: 0.6867\n",
            "Epoch 84/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7249 - accuracy: 0.6867\n",
            "Epoch 85/300\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.7200 - accuracy: 0.6867\n",
            "Epoch 86/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7150 - accuracy: 0.6867\n",
            "Epoch 87/300\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.7099 - accuracy: 0.6867\n",
            "Epoch 88/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7050 - accuracy: 0.6867\n",
            "Epoch 89/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7001 - accuracy: 0.6867\n",
            "Epoch 90/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6953 - accuracy: 0.6933\n",
            "Epoch 91/300\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.6905 - accuracy: 0.6933\n",
            "Epoch 92/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6858 - accuracy: 0.6933\n",
            "Epoch 93/300\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.6811 - accuracy: 0.7000\n",
            "Epoch 94/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6765 - accuracy: 0.7000\n",
            "Epoch 95/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6718 - accuracy: 0.7000\n",
            "Epoch 96/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6675 - accuracy: 0.7000\n",
            "Epoch 97/300\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.6629 - accuracy: 0.7000\n",
            "Epoch 98/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6584 - accuracy: 0.7067\n",
            "Epoch 99/300\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6542 - accuracy: 0.7067\n",
            "Epoch 100/300\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.6499 - accuracy: 0.7067\n",
            "Epoch 101/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6456 - accuracy: 0.7067\n",
            "Epoch 102/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6416 - accuracy: 0.7067\n",
            "Epoch 103/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6374 - accuracy: 0.7067\n",
            "Epoch 104/300\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.6333 - accuracy: 0.7067\n",
            "Epoch 105/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6294 - accuracy: 0.7067\n",
            "Epoch 106/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6254 - accuracy: 0.7133\n",
            "Epoch 107/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6215 - accuracy: 0.7133\n",
            "Epoch 108/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6178 - accuracy: 0.7067\n",
            "Epoch 109/300\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.6139 - accuracy: 0.7067\n",
            "Epoch 110/300\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.6103 - accuracy: 0.7200\n",
            "Epoch 111/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6066 - accuracy: 0.7267\n",
            "Epoch 112/300\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.6031 - accuracy: 0.7267\n",
            "Epoch 113/300\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.5997 - accuracy: 0.7267\n",
            "Epoch 114/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5961 - accuracy: 0.7267\n",
            "Epoch 115/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5927 - accuracy: 0.7267\n",
            "Epoch 116/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5894 - accuracy: 0.7267\n",
            "Epoch 117/300\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5861 - accuracy: 0.7267\n",
            "Epoch 118/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5828 - accuracy: 0.7267\n",
            "Epoch 119/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5796 - accuracy: 0.7267\n",
            "Epoch 120/300\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5765 - accuracy: 0.7267\n",
            "Epoch 121/300\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5734 - accuracy: 0.7267\n",
            "Epoch 122/300\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.5705 - accuracy: 0.7267\n",
            "Epoch 123/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5673 - accuracy: 0.7267\n",
            "Epoch 124/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5644 - accuracy: 0.7267\n",
            "Epoch 125/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5616 - accuracy: 0.7267\n",
            "Epoch 126/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5588 - accuracy: 0.7267\n",
            "Epoch 127/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5559 - accuracy: 0.7267\n",
            "Epoch 128/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5532 - accuracy: 0.7333\n",
            "Epoch 129/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5505 - accuracy: 0.7333\n",
            "Epoch 130/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5478 - accuracy: 0.7400\n",
            "Epoch 131/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5452 - accuracy: 0.7400\n",
            "Epoch 132/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5426 - accuracy: 0.7467\n",
            "Epoch 133/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5401 - accuracy: 0.7467\n",
            "Epoch 134/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5376 - accuracy: 0.7533\n",
            "Epoch 135/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5352 - accuracy: 0.7533\n",
            "Epoch 136/300\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5327 - accuracy: 0.7600\n",
            "Epoch 137/300\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5303 - accuracy: 0.7667\n",
            "Epoch 138/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5280 - accuracy: 0.7667\n",
            "Epoch 139/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5257 - accuracy: 0.7667\n",
            "Epoch 140/300\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5234 - accuracy: 0.7667\n",
            "Epoch 141/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5213 - accuracy: 0.7667\n",
            "Epoch 142/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5190 - accuracy: 0.7667\n",
            "Epoch 143/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5168 - accuracy: 0.7667\n",
            "Epoch 144/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5147 - accuracy: 0.7667\n",
            "Epoch 145/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5126 - accuracy: 0.7733\n",
            "Epoch 146/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5104 - accuracy: 0.7733\n",
            "Epoch 147/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5084 - accuracy: 0.7733\n",
            "Epoch 148/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5064 - accuracy: 0.7733\n",
            "Epoch 149/300\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5044 - accuracy: 0.7800\n",
            "Epoch 150/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5024 - accuracy: 0.7800\n",
            "Epoch 151/300\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.5005 - accuracy: 0.7800\n",
            "Epoch 152/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4986 - accuracy: 0.7800\n",
            "Epoch 153/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4968 - accuracy: 0.7867\n",
            "Epoch 154/300\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.4949 - accuracy: 0.7933\n",
            "Epoch 155/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4931 - accuracy: 0.7933\n",
            "Epoch 156/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4913 - accuracy: 0.7933\n",
            "Epoch 157/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4895 - accuracy: 0.7933\n",
            "Epoch 158/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4879 - accuracy: 0.7933\n",
            "Epoch 159/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4861 - accuracy: 0.7933\n",
            "Epoch 160/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4844 - accuracy: 0.7933\n",
            "Epoch 161/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4827 - accuracy: 0.7933\n",
            "Epoch 162/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4811 - accuracy: 0.7933\n",
            "Epoch 163/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4794 - accuracy: 0.7933\n",
            "Epoch 164/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4778 - accuracy: 0.7933\n",
            "Epoch 165/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4763 - accuracy: 0.7933\n",
            "Epoch 166/300\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4747 - accuracy: 0.7933\n",
            "Epoch 167/300\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.4732 - accuracy: 0.8000\n",
            "Epoch 168/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4717 - accuracy: 0.8000\n",
            "Epoch 169/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4701 - accuracy: 0.8000\n",
            "Epoch 170/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4686 - accuracy: 0.8000\n",
            "Epoch 171/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4672 - accuracy: 0.8067\n",
            "Epoch 172/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4658 - accuracy: 0.8200\n",
            "Epoch 173/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4643 - accuracy: 0.8200\n",
            "Epoch 174/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4629 - accuracy: 0.8200\n",
            "Epoch 175/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4615 - accuracy: 0.8200\n",
            "Epoch 176/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4602 - accuracy: 0.8200\n",
            "Epoch 177/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4588 - accuracy: 0.8267\n",
            "Epoch 178/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4575 - accuracy: 0.8267\n",
            "Epoch 179/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4562 - accuracy: 0.8200\n",
            "Epoch 180/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4548 - accuracy: 0.8200\n",
            "Epoch 181/300\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4535 - accuracy: 0.8200\n",
            "Epoch 182/300\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.4522 - accuracy: 0.8200\n",
            "Epoch 183/300\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4510 - accuracy: 0.8200\n",
            "Epoch 184/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4497 - accuracy: 0.8200\n",
            "Epoch 185/300\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4485 - accuracy: 0.8200\n",
            "Epoch 186/300\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.4473 - accuracy: 0.8200\n",
            "Epoch 187/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4463 - accuracy: 0.8267\n",
            "Epoch 188/300\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.4449 - accuracy: 0.8267\n",
            "Epoch 189/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4439 - accuracy: 0.8267\n",
            "Epoch 190/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4425 - accuracy: 0.8267\n",
            "Epoch 191/300\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.4414 - accuracy: 0.8267\n",
            "Epoch 192/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4402 - accuracy: 0.8333\n",
            "Epoch 193/300\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.4392 - accuracy: 0.8333\n",
            "Epoch 194/300\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4380 - accuracy: 0.8333\n",
            "Epoch 195/300\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4369 - accuracy: 0.8333\n",
            "Epoch 196/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4358 - accuracy: 0.8333\n",
            "Epoch 197/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4347 - accuracy: 0.8333\n",
            "Epoch 198/300\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.4336 - accuracy: 0.8333\n",
            "Epoch 199/300\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4325 - accuracy: 0.8333\n",
            "Epoch 200/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4315 - accuracy: 0.8333\n",
            "Epoch 201/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4305 - accuracy: 0.8333\n",
            "Epoch 202/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4296 - accuracy: 0.8333\n",
            "Epoch 203/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4284 - accuracy: 0.8333\n",
            "Epoch 204/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4274 - accuracy: 0.8333\n",
            "Epoch 205/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4265 - accuracy: 0.8333\n",
            "Epoch 206/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4255 - accuracy: 0.8333\n",
            "Epoch 207/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4245 - accuracy: 0.8333\n",
            "Epoch 208/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4236 - accuracy: 0.8333\n",
            "Epoch 209/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4226 - accuracy: 0.8333\n",
            "Epoch 210/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4216 - accuracy: 0.8400\n",
            "Epoch 211/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4206 - accuracy: 0.8467\n",
            "Epoch 212/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4197 - accuracy: 0.8467\n",
            "Epoch 213/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4188 - accuracy: 0.8467\n",
            "Epoch 214/300\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4178 - accuracy: 0.8467\n",
            "Epoch 215/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4169 - accuracy: 0.8467\n",
            "Epoch 216/300\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4160 - accuracy: 0.8467\n",
            "Epoch 217/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4151 - accuracy: 0.8467\n",
            "Epoch 218/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4142 - accuracy: 0.8467\n",
            "Epoch 219/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4133 - accuracy: 0.8467\n",
            "Epoch 220/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4124 - accuracy: 0.8467\n",
            "Epoch 221/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4115 - accuracy: 0.8533\n",
            "Epoch 222/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4107 - accuracy: 0.8533\n",
            "Epoch 223/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4098 - accuracy: 0.8533\n",
            "Epoch 224/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4089 - accuracy: 0.8533\n",
            "Epoch 225/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4081 - accuracy: 0.8533\n",
            "Epoch 226/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4072 - accuracy: 0.8533\n",
            "Epoch 227/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4063 - accuracy: 0.8533\n",
            "Epoch 228/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4055 - accuracy: 0.8533\n",
            "Epoch 229/300\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4047 - accuracy: 0.8533\n",
            "Epoch 230/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4038 - accuracy: 0.8533\n",
            "Epoch 231/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4030 - accuracy: 0.8533\n",
            "Epoch 232/300\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.4022 - accuracy: 0.8600\n",
            "Epoch 233/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4014 - accuracy: 0.8600\n",
            "Epoch 234/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4006 - accuracy: 0.8600\n",
            "Epoch 235/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3997 - accuracy: 0.8600\n",
            "Epoch 236/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3991 - accuracy: 0.8600\n",
            "Epoch 237/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3982 - accuracy: 0.8667\n",
            "Epoch 238/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3974 - accuracy: 0.8600\n",
            "Epoch 239/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3966 - accuracy: 0.8600\n",
            "Epoch 240/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3959 - accuracy: 0.8600\n",
            "Epoch 241/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3952 - accuracy: 0.8600\n",
            "Epoch 242/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3943 - accuracy: 0.8667\n",
            "Epoch 243/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3936 - accuracy: 0.8600\n",
            "Epoch 244/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3928 - accuracy: 0.8667\n",
            "Epoch 245/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3920 - accuracy: 0.8667\n",
            "Epoch 246/300\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.3912 - accuracy: 0.8667\n",
            "Epoch 247/300\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.3906 - accuracy: 0.8667\n",
            "Epoch 248/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3898 - accuracy: 0.8667\n",
            "Epoch 249/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3891 - accuracy: 0.8667\n",
            "Epoch 250/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3884 - accuracy: 0.8667\n",
            "Epoch 251/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3876 - accuracy: 0.8667\n",
            "Epoch 252/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3868 - accuracy: 0.8667\n",
            "Epoch 253/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3861 - accuracy: 0.8667\n",
            "Epoch 254/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3854 - accuracy: 0.8667\n",
            "Epoch 255/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3846 - accuracy: 0.8667\n",
            "Epoch 256/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3840 - accuracy: 0.8667\n",
            "Epoch 257/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3833 - accuracy: 0.8667\n",
            "Epoch 258/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3825 - accuracy: 0.8667\n",
            "Epoch 259/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3818 - accuracy: 0.8667\n",
            "Epoch 260/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3811 - accuracy: 0.8733\n",
            "Epoch 261/300\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.3804 - accuracy: 0.8733\n",
            "Epoch 262/300\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.3797 - accuracy: 0.8733\n",
            "Epoch 263/300\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.3790 - accuracy: 0.8733\n",
            "Epoch 264/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3783 - accuracy: 0.8733\n",
            "Epoch 265/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.3777 - accuracy: 0.8800\n",
            "Epoch 266/300\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.3770 - accuracy: 0.8800\n",
            "Epoch 267/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3763 - accuracy: 0.8733\n",
            "Epoch 268/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.3756 - accuracy: 0.8733\n",
            "Epoch 269/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.3749 - accuracy: 0.8733\n",
            "Epoch 270/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3743 - accuracy: 0.8733\n",
            "Epoch 271/300\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.3736 - accuracy: 0.8733\n",
            "Epoch 272/300\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.3729 - accuracy: 0.8733\n",
            "Epoch 273/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3723 - accuracy: 0.8733\n",
            "Epoch 274/300\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.3716 - accuracy: 0.8800\n",
            "Epoch 275/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3709 - accuracy: 0.8800\n",
            "Epoch 276/300\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.3703 - accuracy: 0.8867\n",
            "Epoch 277/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3696 - accuracy: 0.8867\n",
            "Epoch 278/300\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.3690 - accuracy: 0.8867\n",
            "Epoch 279/300\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.3683 - accuracy: 0.8867\n",
            "Epoch 280/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3676 - accuracy: 0.8867\n",
            "Epoch 281/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3670 - accuracy: 0.8867\n",
            "Epoch 282/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3663 - accuracy: 0.8867\n",
            "Epoch 283/300\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.3657 - accuracy: 0.8867\n",
            "Epoch 284/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3650 - accuracy: 0.8867\n",
            "Epoch 285/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3644 - accuracy: 0.8867\n",
            "Epoch 286/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3637 - accuracy: 0.8867\n",
            "Epoch 287/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3630 - accuracy: 0.8867\n",
            "Epoch 288/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3624 - accuracy: 0.8867\n",
            "Epoch 289/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3618 - accuracy: 0.8867\n",
            "Epoch 290/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.3613 - accuracy: 0.8867\n",
            "Epoch 291/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.3605 - accuracy: 0.8867\n",
            "Epoch 292/300\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3599 - accuracy: 0.8867\n",
            "Epoch 293/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3593 - accuracy: 0.8867\n",
            "Epoch 294/300\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.3586 - accuracy: 0.8867\n",
            "Epoch 295/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3581 - accuracy: 0.8867\n",
            "Epoch 296/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3574 - accuracy: 0.8867\n",
            "Epoch 297/300\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.3569 - accuracy: 0.8867\n",
            "Epoch 298/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3562 - accuracy: 0.8867\n",
            "Epoch 299/300\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.3556 - accuracy: 0.8867\n",
            "Epoch 300/300\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.3549 - accuracy: 0.8867\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0360e10110>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"final_iris_model.h5\")"
      ],
      "metadata": {
        "id": "Nf61jegEyPma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#essentially saving the scaler in order to apply it on the new data\n",
        "import joblib\n",
        "joblib.dump(scaler,'iris_scaler.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EEJ9_72nyfg4",
        "outputId": "82b15a30-99a7-4262-db99-adb9b1155a3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['iris_scaler.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#predicting on a new flower never seen before on our model"
      ],
      "metadata": {
        "id": "gt8no7Zqyljs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model"
      ],
      "metadata": {
        "id": "bPflMNmwy3mG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flower_model = load_model(\"final_iris_model.h5\")\n",
        "flower_scaler = joblib.load(\"iris_scaler.pkl\")"
      ],
      "metadata": {
        "id": "oBC3qBNoy4u5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "37mn2uQVy58A",
        "outputId": "c4a3fa5f-a097-4f86-a3fd-2b7bd8bf6cf6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal_length</th>\n",
              "      <th>sepal_width</th>\n",
              "      <th>petal_length</th>\n",
              "      <th>petal_width</th>\n",
              "      <th>species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sepal_length  sepal_width  petal_length  petal_width species\n",
              "0           5.1          3.5           1.4          0.2  setosa"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "flower_example = {'sepal_length':5.1,\n",
        "                 'sepal_width':3.5,\n",
        "                 'petal_length':1.4,\n",
        "                 'petal_width':0.2}"
      ],
      "metadata": {
        "id": "dW9aelOUzAHU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "odC3GvrE2DoD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def return_prediction(model,scaler,sample_json):\n",
        "    \n",
        "    # For larger data features, you should probably write a for loop\n",
        "    # That builds out this array for you\n",
        "    \n",
        "    s_len = sample_json['sepal_length']\n",
        "    s_wid = sample_json['sepal_width']\n",
        "    p_len = sample_json['petal_length']\n",
        "    p_wid = sample_json['petal_width']\n",
        "    \n",
        "    flower = [[s_len,s_wid,p_len,p_wid]]\n",
        "    \n",
        "    flower = scaler.transform(flower)\n",
        "    \n",
        "    classes = np.array(['setosa', 'versicolor', 'virginica'])\n",
        "  \n",
        "    predict_x=model.predict(flower) \n",
        "    class_ind =np.argmax(predict_x,axis=1)\n",
        "    \n",
        "    return classes[class_ind][0]\n",
        "                    \n",
        "    "
      ],
      "metadata": {
        "id": "HxAPJ02tzxE_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "return_prediction(flower_model,flower_scaler,flower_example)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "LUx_1gSX1gMT",
        "outputId": "dee98fa1-32f8-4952-bb2e-22b6adb755ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'setosa'"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#code for deployment"
      ],
      "metadata": {
        "id": "Ra33jOvQ1l6r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m91_QRSc3UUf",
        "outputId": "ea2a30e4-6c58-4cad-a51e-3c83c1584bb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.7.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.7.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.13.3)\n",
            "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.7.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.42.0)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.19.5)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (12.0.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.12.0)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.7.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.10.0.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.37.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.22.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (1.8.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (3.3.6)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (57.4.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (1.35.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow) (4.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow) (3.6.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2021.10.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (3.1.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "import joblib\n",
        "\n",
        "flower_model = load_model(\"final_iris_model.h5\")\n",
        "flower_scaler = joblib.load(\"iris_scaler.pkl\")\n",
        "\n",
        "def return_prediction(model,scaler,sample_json):\n",
        "    \n",
        "    # For larger data features, you should probably write a for loop\n",
        "    # That builds out this array for you\n",
        "    \n",
        "    s_len = sample_json['sepal_length']\n",
        "    s_wid = sample_json['sepal_width']\n",
        "    p_len = sample_json['petal_length']\n",
        "    p_wid = sample_json['petal_width']\n",
        "    \n",
        "    flower = [[s_len,s_wid,p_len,p_wid]]\n",
        "    flower = scaler.transform(flower)\n",
        "    classes = np.array(['setosa', 'versicolor', 'virginica'])\n",
        "    \n",
        "    predict_x=model.predict(flower) \n",
        "    class_ind =np.argmax(predict_x,axis=1)\n",
        "    \n",
        "    return classes[class_ind]"
      ],
      "metadata": {
        "id": "-TNss2m52-yE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "2tWohPBc4JR2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}